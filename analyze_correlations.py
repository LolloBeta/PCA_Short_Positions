# -*- coding: utf-8 -*-
"""analyze_correlations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BIebhbNMDEeo0TIF7fnffaznyXnSxodU
"""

import argparse
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(1)
plt.style.use('seaborn-v0_8-whitegrid')
COVERAGE_MIN = 0.8  # Minimum data coverage per stock
SUBN = 40  # Submatrix size
SAMPLES = 60  # Number of samples per period
PERIODS = [('1994-01-01', '1998-12-31'),('1999-01-01', '2003-12-31'),('2004-01-01', '2008-12-31'),('2009-01-01', '2013-12-31')]


def parse_args(): # Parse command line arguments
    parser = argparse.ArgumentParser(description='Analyze S&P 500 correlations')
    parser.add_argument('--data', required=True, help='Path to sp500_adj_close_wide.csv')
    parser.add_argument('--no-plots', action='store_true', help='Skip generating heatmaps')
    return parser.parse_args()


def load_data(filepath): # Load S&P 500 dataset from CSV file
    df = pd.read_csv(filepath, index_col=0, parse_dates=True)
    dates = df.index
    prices = df.values
    return dates, prices


def filter_by_coverage(prices, min_coverage=0.8): # Filter stocks with sufficient data coverage.
    valid_counts = np.sum(~np.isnan(prices), axis=0)
    valid_mask = valid_counts >= (min_coverage * prices.shape[0])
    return prices[:, valid_mask]


def log_returns(prices): # Calculate logarithmic returns
    return np.diff(np.log(prices), axis=0)


def classify_correlation_matrix(corr_matrix):
    """
    Classify correlation matrix into three classes:
    - Class I: All correlations positive
    - Class II: Some negative correlations, but first eigenvector all positive
    - Class III: First eigenvector contains negative elements (short positions)

    Returns: (class, eigenvector, neg_pct, neg_mag)
    """
    n = corr_matrix.shape[0]
    upper_tri = corr_matrix[np.triu_indices(n, k=1)]
    neg_mask = upper_tri < 0
    neg_pct = 100 * np.mean(neg_mask)
    neg_mag = np.mean(np.abs(upper_tri[neg_mask])) if np.any(neg_mask) else 0

    if not np.any(neg_mask): # Class I: No negative correlations (Perron-Frobenius theorem)
        return 1, None, neg_pct, neg_mag

    eigenvalues, eigenvectors = np.linalg.eig(corr_matrix) # Compute first eigenvector
    v1 = eigenvectors[:, np.argmax(eigenvalues)].real

    if np.all(v1 >= 0): # Class II: All positive eigenvector elements
        return 2, v1, neg_pct, neg_mag

    return 3, v1, neg_pct, neg_mag # Class III: Contains negative elements


def analyze_period(dates, prices, start_date, end_date, period_name, save_plots=True): # Analyze correlations for a specific period.
    mask = (dates >= pd.to_datetime(start_date)) & (dates <= pd.to_datetime(end_date)) # Filter period
    prices_period = prices[mask, :]
    prices_filtered = filter_by_coverage(prices_period, COVERAGE_MIN) # Filter by coverage and compute returns
    n_stocks = prices_filtered.shape[1]
    returns = log_returns(prices_filtered)
    if n_stocks < 3 or returns.shape[0] < 2:
        print(f"Period {period_name}: insufficient data")
        return None
    corr_full = np.corrcoef(returns, rowvar=False) # Full correlation matrix
    upper_tri = corr_full[np.triu_indices(n_stocks, k=1)]
    neg_pct_full = 100 * np.mean(upper_tri < 0)
    print(f"Period {period_name}: {n_stocks} stocks, {neg_pct_full:.2f}% negative correlations")

    if save_plots: # Save heatmap
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_full, cmap='RdBu_r', center=0, vmin=-1, vmax=1, square=True, cbar_kws={'label': 'Correlation'})
        plt.title(f'Correlation Matrix {period_name}')
        plt.tight_layout()
        plt.savefig(f'correlations_{period_name.replace("–", "_")}.png', dpi=300, bbox_inches='tight')
        plt.close()

    counts = {'I': 0, 'II': 0, 'III': 0} # Sample and classify submatrices
    stats_II = {'neg_pct': [], 'neg_mag': []}
    stats_III = {'neg_pct': [], 'neg_mag': []}
    subn = min(SUBN, n_stocks)
    for _ in range(SAMPLES):
        idx_sample = np.random.choice(n_stocks, size=subn, replace=False)
        corr_sample = np.corrcoef(returns[:, idx_sample], rowvar=False)
        class_type, v1, neg_pct, neg_mag = classify_correlation_matrix(corr_sample)
        if class_type == 1:
            counts['I'] += 1
        elif class_type == 2:
            counts['II'] += 1
            stats_II['neg_pct'].append(neg_pct)
            stats_II['neg_mag'].append(neg_mag)
        else:
            counts['III'] += 1
            stats_III['neg_pct'].append(neg_pct)
            stats_III['neg_mag'].append(neg_mag)
    return {
        'period': period_name,
        'n_stocks': n_stocks,
        'neg_pct_full': neg_pct_full,
        'counts': counts,
        'stats_II': stats_II,
        'stats_III': stats_III
    }


def print_results(results):
    print("Period\tClassI\tClassII\tClassIII") # Table 1: count of classes per period
    for r in results:
        c = r['counts']
        print(f"{r['period']}\t{c['I']}\t{c['II']}\t{c['III']}")

    all_ii_pct, all_ii_mag = [], [] # Table 2: Average neg% and magnitude
    all_iii_pct, all_iii_mag = [], []
    for r in results:
        all_ii_pct.extend(r['stats_II']['neg_pct'])
        all_ii_mag.extend(r['stats_II']['neg_mag'])
        all_iii_pct.extend(r['stats_III']['neg_pct'])
        all_iii_mag.extend(r['stats_III']['neg_mag'])
    def _mean(x):
        return sum(x)/len(x) if x else float('nan')
    m_ii_pct  = _mean(all_ii_pct)
    m_ii_mag  = _mean(all_ii_mag)
    m_iii_pct = _mean(all_iii_pct)
    m_iii_mag = _mean(all_iii_mag)
    print("\nClass\tNegPctMean\tNegMagMean")
    if all_ii_pct or all_ii_mag:
        print(f"II\t{m_ii_pct:.4f}\t{m_ii_mag:.6f}")
    else:
        print("II\tNA\tNA")
    if all_iii_pct or all_iii_mag:
        print(f"III\t{m_iii_pct:.4f}\t{m_iii_mag:.6f}")
    else:
        print("III\tNA\tNA")



def main():
    args = parse_args()
    dates, prices = load_data(args.data) # Load data
    print(f"Loaded: {len(dates)} days, {prices.shape[1]} stocks\n")
    results = []
    for start_date, end_date in PERIODS: # Analyze each period
        period_name = f"{start_date[:4]}–{end_date[:4]}"
        result = analyze_period(dates, prices, start_date, end_date, period_name,
                               save_plots=not args.no_plots)
        if result:
            results.append(result)
    print_results(results) # Print summary tables
    if not args.no_plots:
        print("\nHeatmaps saved as PNG files.")